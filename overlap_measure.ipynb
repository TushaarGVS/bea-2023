{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_f = open(os.path.join(\"data\", \"raw\", f\"train_with-reference.jsonl\"), \"r\")\n",
    "data = []\n",
    "for line in train_f:\n",
    "    data.append(json.loads(line))\n",
    "train_f.close()\n",
    "\n",
    "dev_f = open(os.path.join(\"data\", \"raw\", f\"dev_without-reference.jsonl\"), \"r\")\n",
    "dev_data = []\n",
    "for line in dev_f:\n",
    "    dev_data.append(json.loads(line))\n",
    "dev_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import tee\n",
    "\n",
    "def triplewise(iterable):\n",
    "    a, b, c = tee(iterable, 3)\n",
    "    next(b, None)\n",
    "    next(c, None)\n",
    "    next(c, None)\n",
    "    return zip(a, b, c)\n",
    "\n",
    "def get_trigrams(convo):\n",
    "    texts = [utterance['text'] for utterance in convo['utterances']]\n",
    "    trigrams = set(triplewise(texts))\n",
    "    return trigrams\n",
    "\n",
    "def has_overlap(convo1, convo2):\n",
    "    convo1_trigrams = get_trigrams(convo1)\n",
    "    convo2_trigrams = get_trigrams(convo2)\n",
    "\n",
    "    return bool(convo1_trigrams.intersection(convo2_trigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "test_size = int(0.1 * len(data))\n",
    "\n",
    "train_data = data[test_size:]\n",
    "test_data = data[:test_size]\n",
    "\n",
    "for convo_test in test_data:\n",
    "    for convo_train in train_data:\n",
    "        if has_overlap(convo_test, convo_train):\n",
    "            train_data.remove(convo_train)\n",
    "            test_data.append(convo_train)\n",
    "\n",
    "print(\"Train set size:\", len(train_data))\n",
    "print(\"Test set size:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlaps between train and dev: 1236\n"
     ]
    }
   ],
   "source": [
    "# check overlap between train and dev\n",
    "count = 0\n",
    "ids = set()\n",
    "for convo in train_data:\n",
    "    for train_convo in train_data:\n",
    "        if train_convo != convo and has_overlap(convo, train_convo):\n",
    "            count += 1\n",
    "            ids.add(convo['id'])\n",
    "    #         print(\"Overlap found!\", convo['id'], train_convo['id'])\n",
    "    #         # print the 2 utterances and the 3 utterances that overlap\n",
    "    #         print (\"Convo 1:\", convo['utterances'])\n",
    "    #         print (\"Convo 2:\", train_convo['utterances'])\n",
    "    #         print (\"Overlap:\", get_trigrams(convo).intersection(get_trigrams(train_convo)))\n",
    "    #         break\n",
    "    # break\n",
    "print (\"Number of overlaps between train and dev:\", len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import tee\n",
    "\n",
    "def triplewise(iterable):\n",
    "    a, b, c = tee(iterable, 3)\n",
    "    next(b, None)\n",
    "    next(c, None)\n",
    "    next(c, None)\n",
    "    return zip(a, b, c)\n",
    "\n",
    "def get_trigrams(convo):\n",
    "    texts = [utterance['content'] for utterance in convo['context']]\n",
    "    trigrams = set(triplewise(texts))\n",
    "    return trigrams\n",
    "\n",
    "def has_overlap(convo1, convo2):\n",
    "    convo1_trigrams = get_trigrams(convo1)\n",
    "    convo2_trigrams = get_trigrams(convo2)\n",
    "\n",
    "    return bool(convo1_trigrams.intersection(convo2_trigrams))\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"train\": [],\n",
    "    \"dev\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "dataset_names = {\n",
    "    \"train\": \"train_with-reference\",\n",
    "    \"dev\": \"dev_without-reference\"\n",
    "}\n",
    "\n",
    "## sample prompt object\n",
    "\n",
    "# messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "#         {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "#     ]\n",
    "\n",
    "\n",
    "for split in dataset_names:\n",
    "    with open(os.path.join(\"data\", \"raw\", f\"{dataset_names[split]}.jsonl\"), \"r\") as f:\n",
    "        for line in f:\n",
    "            data_line = json.loads(line)\n",
    "            sample = {\"context\": \"\", \"response\": \"\", \"dialogRPTcontext\": \"\", \"dialogRPTresponse\": \"\"}\n",
    "            utterances = data_line[\"utterances\"]\n",
    "            # [{'text': 'A) pull through', 'speaker': 'student'}, {'text': 'OK great', 'speaker': 'teacher'}, {'text': 'Not sure about the meaning of the second one... Does that person mean that being the prime minister he had to survive??', 'speaker': 'student'}] {'text': 'Ah yes good question - this is a bit ambiguous....', 'speaker': 'teacher'}\n",
    "            # sample[\"context\"] = \"\\n\".join([f\"{x['speaker']}: {x['text']}\" for x in utterances])\n",
    "            # make sample context into a prompt object\n",
    "            sample[\"context\"] = []\n",
    "            for i in range(len(utterances)):\n",
    "                if utterances[i]['speaker'] == 'student':\n",
    "                    # sample[\"context\"].append({\"role\": \"user\", \"content\": \"new utterance\"})\n",
    "                    sample[\"context\"].append({\"role\": \"user\", \"content\": utterances[i]['speaker'] + \": \" + utterances[i][\"text\"]})\n",
    "                else:\n",
    "                    sample[\"context\"].append({\"role\": \"assistant\", \"content\": utterances[i]['speaker'] + \": \" + utterances[i][\"text\"]})\n",
    "                    \n",
    "            dialogRPTcontext = ''\n",
    "            for dialogue_line in utterances:\n",
    "                dialogRPTcontext += \"'\" + dialogue_line['speaker'] + \"': \" + dialogue_line['text'] + ' <|endoftext|> '\n",
    "            sample[\"dialogRPTcontext\"] = dialogRPTcontext\n",
    "                        \n",
    "            \n",
    "            if \"response\" in data_line.keys():\n",
    "                response = data_line[\"response\"]\n",
    "                sample[\"response\"] = response['speaker'] + \": \" + response['text']\n",
    "                \n",
    "                dialogRPTresponse = \"'\" + response['speaker'] + \"': \" + response['text'] + ' <|endoftext|> ' \n",
    "                sample[\"dialogRPTresponse\"] = dialogRPTresponse \n",
    "\n",
    "            # print (sample)\n",
    "            data[split].append(sample)\n",
    "            \n",
    "# now split the train set into train and test using the overlap measure\n",
    "random.shuffle(data[\"train\"])\n",
    "test_size = int(0.05 * len(data[\"train\"]))\n",
    "train_data = data[\"train\"][test_size:]\n",
    "test_data = data[\"train\"][:test_size]\n",
    "\n",
    "for convo_test in test_data:\n",
    "    for convo_train in train_data:\n",
    "        if has_overlap(convo_test, convo_train):\n",
    "            train_data.remove(convo_train)\n",
    "            test_data.append(convo_train)\n",
    "            \n",
    "data['train'] = train_data\n",
    "data['test'] = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2147\n",
      "Test set size: 600\n",
      "Dev set size: 305\n",
      "Train ratio: 0.7815799053512923\n",
      "Test ratio: 0.21842009464870768\n",
      "Dev ratio: 0.09993446920052425\n"
     ]
    }
   ],
   "source": [
    "print (\"Train set size:\", len(data['train']))\n",
    "print (\"Test set size:\", len(data['test']))\n",
    "print (\"Dev set size:\", len(data['dev']))\n",
    "\n",
    "# ratios\n",
    "print (\"Train ratio:\", len(data['train']) / (len(data['train']) + len(data['test']) + len(data['dev'])))\n",
    "print (\"Test ratio:\", len(data['test']) / (len(data['train']) + len(data['test']) + len(data['dev'])))\n",
    "print (\"Dev ratio:\", len(data['dev']) / (len(data['train']) + len(data['test']) + len(data['dev'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
